import os
import glob
import streamlit as st
import sys
import pysqlite3

# pysqlite3'Ã¼ sistemin varsayÄ±lan sqlite3'Ã¼ olarak ayarla
sys.modules["sqlite3"] = sys.modules["pysqlite3"]

# Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±n
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader, UnstructuredImageLoader, WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationSummaryMemory
from langchain.prompts import PromptTemplate
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_community.vectorstores.utils import filter_complex_metadata

# --- RAG Sisteminin HazÄ±rlanmasÄ± ---
@st.cache_resource
def setup_rag_system():
    # TÃ¼m durum mesajlarÄ±nÄ± iÃ§eren kalÄ±cÄ± bir kapsayÄ±cÄ± oluÅŸturun
    info_container = st.empty()
    
    with info_container.container():
        st.info("Sistem baÅŸlatÄ±lÄ±yor...")

        db_path = "./chroma_db"
        files_dir = "./files"
        
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        
        # Mevcut veritabanÄ±nÄ± yÃ¼klemeyi dene
        if os.path.exists(db_path) and os.path.isdir(db_path):
            try:
                st.info("Mevcut veritabanÄ± bulunuyor. YÃ¼kleniyor...")
                vectorstore = Chroma(
                    collection_name="parent_child_collection",
                    embedding_function=embeddings,
                    persist_directory=db_path
                )
                retriever = vectorstore.as_retriever(search_kwargs={"k": 15})
                st.success("VeritabanÄ± baÅŸarÄ±yla yÃ¼klendi.")
                return retriever
            except Exception as e:
                st.warning(f"VeritabanÄ± yÃ¼klenirken bir hata oluÅŸtu: {e}. Yeniden oluÅŸturuluyor...")
                
        st.info("VeritabanÄ± bulunamadÄ± veya yÃ¼klenemedi. Yeni bir veritabanÄ± oluÅŸturuluyor...")
        image_files = glob.glob(os.path.join(files_dir, "*.png")) + glob.glob(os.path.join(files_dir, "*.jpg"))
        # PDF ve resim dosyalarÄ±nÄ± yÃ¼kle
        pdf_files = glob.glob(os.path.join(files_dir, "*.pdf"))
        
        all_documents = []
        if image_files:
            for file_path in image_files:
                st.info(f"'{os.path.basename(file_path)}' resim dosyasÄ± yÃ¼kleniyor...")
                # Resim dosyalarÄ±ndan metin Ã§Ä±karmak iÃ§in UnstructuredImageLoader kullanÄ±n
                loader = UnstructuredImageLoader(file_path)
                all_documents.extend(loader.load())
        if pdf_files:
            for file_path in pdf_files:
                st.info(f"'{os.path.basename(file_path)}' dosyasÄ± yÃ¼kleniyor...")
                # Metin PDF'leri iÃ§in PyPDFLoader kullanÄ±n
                loader = PyPDFLoader(file_path)
                all_documents.extend(loader.load())

        

        # Web sayfasÄ±nÄ± yÃ¼kle
        web_url = "https://tubitak.gov.tr/tr/yarismalar/2204-lise-ogrencileri-arastirma-projeleri-yarismasi"
        st.info(f"'{web_url}' adresindeki sayfa yÃ¼kleniyor...")
        web_loader = WebBaseLoader(web_url)
        all_documents.extend(web_loader.load())

        if not all_documents:
            st.error("HiÃ§bir belge (PDF veya web sayfasÄ±) yÃ¼klenemedi. LÃ¼tfen dosyalarÄ±nÄ±zÄ±n doÄŸru klasÃ¶rde olduÄŸundan ve URL'nin doÄŸru olduÄŸundan emin olun.")
            return None

        st.success(f"Toplam {len(all_documents)} sayfa yÃ¼klendi.")
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        split_documents = text_splitter.split_documents(all_documents)
        
        # KarmaÅŸÄ±k meta verileri filtreleyin
        filtered_documents = filter_complex_metadata(split_documents)

        vectorstore = Chroma.from_documents(
            documents=filtered_documents,
            embedding=embeddings,
            collection_name="parent_child_collection",
            persist_directory=db_path
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": 30})
        st.success("VeritabanÄ± baÅŸarÄ±yla oluÅŸturuldu.")
        return retriever

# --- Streamlit UygulamasÄ±nÄ±n Ana BÃ¶lÃ¼mÃ¼ ---
st.set_page_config(page_title="YarÄ±ÅŸma AsistanÄ±", layout="wide")

st.title("ğŸ† YarÄ±ÅŸma AsistanÄ±")
st.write("Åartnameler ve raporlar hakkÄ±nda sorularÄ±nÄ±zÄ± sorun.")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
if "llm" not in st.session_state:
    st.session_state.llm = None
if "memory" not in st.session_state:
    st.session_state.memory = None

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

retriever = setup_rag_system()
if retriever:
    if st.session_state.qa_chain is None:
        st.session_state.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.7,
            google_api_key=os.environ.get("GOOGLE_API_KEY")
        )
        st.session_state.memory = ConversationSummaryMemory(
            llm=st.session_state.llm,
            memory_key="chat_history", 
            return_messages=True
        )
        
        custom_prompt_template = """
Sen, TÃœBÄ°TAK 2204-A Lise Ã–ÄŸrencileri AraÅŸtÄ±rma Projeleri YarÄ±ÅŸmasÄ± hakkÄ±nda Ã¶ÄŸrenci ve danÄ±ÅŸmanlara yardÄ±mcÄ± olan bir asistansÄ±n. GÃ¶revin, onlara yarÄ±ÅŸmanÄ±n ÅŸartnameleri, baÅŸvuru ve rapor sÃ¼reÃ§leri gibi konularda, **sadece verilen belgelerden edindiÄŸin bilgilere dayanarak** rehberlik etmektir.
EÄŸer verilen baÄŸlamda sorunun cevabÄ± yoksa, elindeki bilgilere gÃ¶re en mantÄ±klÄ± yanÄ±tÄ± Ã¼retmeye Ã§alÄ±ÅŸ. EÄŸer hiÃ§bir ÅŸekilde ilgili bilgi bulunamÄ±yorsa, kibar bir ÅŸekilde **"Verilen belgelerde bu konuda spesifik bir bilgi bulunmamaktadÄ±r."** ÅŸeklinde yanÄ±t ver. Kesinlikle uydurma bilgi verme. YanÄ±tlarÄ±n profesyonel, anlaÅŸÄ±lÄ±r ve yarÄ±ÅŸma konusuna odaklÄ± olsun.

KonuÅŸma GeÃ§miÅŸi:
{chat_history}

BaÄŸlam:
{context}

Soru:
{question}

YardÄ±mcÄ± AsistanÄ±n CevabÄ±:
"""
        CUSTOM_PROMPT = PromptTemplate(
            template=custom_prompt_template,
            input_variables=["chat_history", "context", "question"]
        )
        
        multi_query_retriever = MultiQueryRetriever.from_llm(
            retriever=retriever,
            llm=st.session_state.llm
        )
        
        st.session_state.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=st.session_state.llm,
            retriever=multi_query_retriever,
            memory=st.session_state.memory,
            rephrase_question=False,
            combine_docs_chain_kwargs={"prompt": CUSTOM_PROMPT} 
        )

    if prompt := st.chat_input("Buraya yazÄ±n..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.spinner("Cevap bekleniyor..."):
            result = st.session_state.qa_chain.invoke({"question": prompt})
            response = result["answer"]
            
        with st.chat_message("assistant"):
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
else:
    st.error("Proje baÅŸlatÄ±lamÄ±yor. LÃ¼tfen gerekli dosyalarÄ±n olduÄŸundan emin olun.")


